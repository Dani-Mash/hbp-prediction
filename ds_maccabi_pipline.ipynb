{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy matplotlib seaborn scipy scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Import & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "# Load the data from the csv file and display the first 5 rows\n",
    "path = '/Users/danielmashala/dev/code/ds_code/Maccabi_Home_Task/ds_assignment_data.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Overview of Columns\n",
    "Identify feature groups and key columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset shape\n",
    "print(f\"Dataset shape: {df.shape[0]} rows, {df.shape[1]} columns\\n\")\n",
    "# Dataset data types\n",
    "dtype_counts = df.dtypes.value_counts()\n",
    "for dtype, count in dtype_counts.items():\n",
    "    print(f\"Number of columns with dtype {dtype}: {count}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Overview of Columns\n",
    "demographic_cols = [col for col in df.columns if col.startswith('demog_')]\n",
    "lab_cols = [col for col in df.columns if col.startswith('lab_')]\n",
    "bp_cols = [col for col in df.columns if col.startswith('measure_blood_pressure')]\n",
    "diagnosis_cols = [col for col in df.columns if 'diag' in col and 'match' not in col]\n",
    "match_cols = [col for col in df.columns if col.startswith('match_')]\n",
    "subtype_cols = [col for col in df.columns if col.endswith('_sum')]\n",
    "clinical_text_col = 'clinical_sheet'\n",
    "target_col = 'Y'\n",
    "print(f'Demographics: {demographic_cols}')\n",
    "print(f'Lab: {lab_cols[:5]} ...')\n",
    "print(f'BP: {bp_cols[:5]} ...')\n",
    "print(f'Diagnosis: {diagnosis_cols[:5]} ...')\n",
    "print(f'Match flags: {match_cols}')\n",
    "print(f'Subtype counts: {subtype_cols}')\n",
    "print(f'Clinical text: {clinical_text_col}')\n",
    "print(f'Target: {target_col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Missingness Analysis\n",
    "Visualize and summarize missing data patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.histplot(missing, bins=30, kde=False)\n",
    "plt.title('Distribution of Missingness Across Features')\n",
    "plt.xlabel('Fraction Missing')\n",
    "plt.ylabel('Number of Features')\n",
    "plt.show()\n",
    "print('Top 20 features with most missing values:')\n",
    "print(missing.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing value fractions for each column\n",
    "missing_fraction = df.isnull().mean()\n",
    "\n",
    "# 1. Number of columns with >80% missing values\n",
    "num_cols_over_80 = (missing_fraction >= 0.8).sum()\n",
    "\n",
    "# 2. Number of columns with no missing values\n",
    "num_cols_no_missing = (missing_fraction == 0).sum()\n",
    "\n",
    "# 3. Number of columns between 0 and 50% missing values\n",
    "num_cols_under_50_over_0 = ((missing_fraction < 0.5) & (missing_fraction > 0)).sum()\n",
    "\n",
    "# 4. Number of columns between 50% and 80% missing values\n",
    "num_cols_over_50_under_80 = ((missing_fraction > 0.5) & (missing_fraction < 0.8)).sum()\n",
    "\n",
    "# 5. Number of columns with >90% missing values\n",
    "num_cols_over_90 = (missing_fraction >= 0.9).sum()\n",
    "\n",
    "print(f\"Columns with no missing values: {num_cols_no_missing}\")\n",
    "print(f\"Columns with 0<cols<50% missing values: {num_cols_under_50_over_0}\")\n",
    "print(f\"Columns with 50%<cols<80% missing values: {num_cols_over_50_under_80}\")\n",
    "print(f\"Columns with >= 80% missing values: {num_cols_over_80}\")\n",
    "print(f\"Columns with >= 90% missing values: {num_cols_over_90}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Target 'Y' Distribution \n",
    "Examine the balance of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_counts = df['Y'].value_counts()\n",
    "y_percentage = df['Y'].value_counts(normalize=True) * 100\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.countplot(x='Y', data=df)\n",
    "plt.title('Target (Y) Distribution')\n",
    "plt.show()\n",
    "\n",
    "print(\"Target (Y) Distribution:\")\n",
    "print(\"Counts:\")\n",
    "print(y_counts)\n",
    "print(\"Percentage:\")\n",
    "print(y_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Variable (Y) – Hypertensive Complications in Pregnancy\n",
    "0 – No complication: 9,568 cases (95.68%)\n",
    "\n",
    "1 – Complication (e.g., preeclampsia, gestational hypertension): 432 cases (4.32%)\n",
    "\n",
    "\n",
    "Insights:\n",
    "\n",
    "This is an imbalanced classification problem – only ~4% positive cases.\n",
    "\n",
    "Focus on metrics beyond accuracy:\n",
    "\n",
    "Recall – catch as many high-risk cases as possible\n",
    "\n",
    "Precision at top-k – to prioritize who should be referred for further examination\n",
    "\n",
    "F1 score – better suited for imbalanced data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of Source Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_cols = [\"match_diag_after\", \"match_measure_after\",\n",
    "             \"match_rasham_after\", \"match_aspirin_after\", \"match_pdf_after\"]\n",
    "\n",
    "y_flags = df[df[\"Y\"] == 1][flag_cols].sum()\n",
    "y_flags_pct = y_flags / y_flags.sum() * 100\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.pie(y_flags_pct, labels=y_flags_pct.index, autopct=\"%1.1f%%\")\n",
    "plt.title(\"Distribution of Diagnosis Sources (Y = 1)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(y_flags_pct.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: Source of Positive Cases (Y = 1)\n",
    "\n",
    "Among the 432 positive cases (Y = 1), the distribution of source flags indicates:\n",
    "\n",
    "- **54% (`match_diag_after`)** were identified via ICD-9 diagnosis codes — the main administrative channel.\n",
    "- **22% (`match_aspirin_after`)** had a low-dose aspirin prescription, typically reflecting clinical suspicion of risk.\n",
    "- **21% (`match_pdf_after`)** were identified from hospital admission/discharge notes — likely more severe cases.\n",
    "- **3% (`match_rasham_after`)** came from general medical registry (\"Rasham\"), suggesting limited documentation via that channel.\n",
    "- **0% (`match_measure_after`)** were flagged solely via blood pressure measurements, indicating BP data is not actively used in current labeling.\n",
    "\n",
    "**Conclusion:** The label (Y) heavily depends on post-week-15 diagnosis codes and clinical documentation. Therefore, early signals such as blood pressure, urine protein, or early lab results are likely underrepresented in Y = 1. This should be taken into account when training a model for early prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Complication Breakdown (Among the 432 Cases Where Y = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtype_columns = [\n",
    "    'secondary_hypertension_sum',\n",
    "    'essential_hypertension_sum',\n",
    "    'hypertensive_heart_disease_sum',\n",
    "    'hypertensive_chronic_kidney_disease_sum',\n",
    "    'hypertensive_heart_and_chronic_kidney_disease_sum',\n",
    "    'pregnancy_hypertension_sum',\n",
    "    'preeclampsia_sum',\n",
    "    'eclampsia_sum'\n",
    "]\n",
    "\n",
    "# Count how many cases of each type occurred (at least one occurrence)\n",
    "subtype_counts = (df[subtype_columns] > 0).sum().sort_values(ascending=False)\n",
    "\n",
    "subtype_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detected sub-complications:\n",
    "\n",
    "- preeclampsia_sum: 128 cases – Preeclampsia, the most common and dangerous complication\n",
    "\n",
    "- pregnancy_hypertension_sum: 111 cases – Gestational hypertension without organ damage\n",
    "\n",
    "- essential_hypertension_sum: 100 cases – Primary hypertension that developed during pregnancy\n",
    "\n",
    "- eclampsia_sum: 17 cases – Severe form of preeclampsia with seizures\n",
    "\n",
    "Sub-complications that did not appear at all:\n",
    "\n",
    "- secondary_hypertension_sum\n",
    "\n",
    "- hypertensive_heart_disease_sum\n",
    "\n",
    "- hypertensive_chronic_kidney_disease_sum\n",
    "\n",
    "- hypertensive_heart_and_chronic_kidney_disease_sum\n",
    "\n",
    "These may be irrelevant for pregnancy or simply not recorded in the dataset.\n",
    "\n",
    "Conclusions:\n",
    "\n",
    "- Preeclampsia is the most common and critical complication to detect.\n",
    "- Eclampsia is rare but very severe – worth considering a model sensitive to extreme cases.\n",
    "- The Y column aggregates all types, but training a separate model for a specific complication (e.g., preeclampsia) might also be valuable depending on the use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Distribution\n",
    "Visualize age distribution by target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing age values if exisit \n",
    "df = pd.read_csv(path)\n",
    "df = df[df[\"demog_customer_age\"].notna()].copy()\n",
    "\n",
    "# Set the age column name (adjust if your column is named differently)\n",
    "age_col = 'demog_customer_age'\n",
    "\n",
    "# Plot age distribution by Y\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(data=df, x=age_col, hue='Y', bins=30, kde=True, stat='density', common_norm=False)\n",
    "plt.title('Age Distribution by Target (Y)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title='Y', labels=['No Complication (0)', 'Complication (1)'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "age_stats = df.groupby('Y')[age_col].agg(['count', 'mean', 'std', 'min', 'max', 'median'])\n",
    "print(age_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "age_0 = df[df['Y'] == 0][age_col]\n",
    "age_1 = df[df['Y'] == 1][age_col]\n",
    "t_stat, p_val = ttest_ind(age_0, age_1, equal_var=False)\n",
    "print(f\"T-test: T-stat={t_stat:.2f} p-value: {p_val:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age and Risk of Hypertensive Disorders\n",
    "To assess the relationship between age and the risk of hypertensive disorders, the distribution of age was compared between patients who developed complications (Y=1) and those who did not (Y=0).\n",
    "\n",
    "Patients with complications had a slightly higher average age (30.8 years) compared to those without complications (29.7 years). The distribution plot shows a modest shift toward older age among the complication group.\n",
    "\n",
    "t-test confirmed that this difference is statistically significant (t = -3.80, p = 0.00016).\n",
    "\n",
    "Conclusion: While the difference in age is small, older maternal age is associated with an increased risk of hypertensive disorders and may contribute useful signal when included as a feature in predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary indicators for each complication\n",
    "df['has_preeclampsia'] = df['preeclampsia_sum'] > 0\n",
    "df['has_pregnancy_htn'] = df['pregnancy_hypertension_sum'] > 0\n",
    "df['has_eclampsia'] = df['eclampsia_sum'] > 0\n",
    "\n",
    "# Create boxplots to compare age across complication categories\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.boxplot(data=df, x='has_preeclampsia', y='demog_customer_age', ax=axes[0])\n",
    "axes[0].set_title(\"Age vs Preeclampsia\")\n",
    "axes[0].set_xticklabels(['No', 'Yes'])\n",
    "\n",
    "sns.boxplot(data=df, x='has_pregnancy_htn', y='demog_customer_age', ax=axes[1])\n",
    "axes[1].set_title(\"Age vs Pregnancy Hypertension\")\n",
    "axes[1].set_xticklabels(['No', 'Yes'])\n",
    "\n",
    "sns.boxplot(data=df, x='has_eclampsia', y='demog_customer_age', ax=axes[2])\n",
    "axes[2].set_title(\"Age vs Eclampsia\")\n",
    "axes[2].set_xticklabels(['No', 'Yes'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot compares age distributions across patients with and without three hypertensive disorder subtypes.\n",
    "\n",
    "Preeclampsia and Pregnancy Hypertension show similar age distributions between affected and unaffected groups, suggesting age is not a strong predictor for these conditions.\n",
    "\n",
    "Eclampsia shows a noticeable shift toward older ages in affected patients, indicating age may play a more important role.\n",
    "\n",
    "Conclusion: Age appears to be more relevant for predicting eclampsia than for other hypertensive disorder subtypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demog_capitationcoefficient Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)\n",
    "\n",
    "# Plot distribution of demog_capitationcoefficient by target\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x=\"Y\", y=\"demog_capitationcoefficient\")\n",
    "plt.title(\"Distribution of Capitation Coefficient by Target (Y)\")\n",
    "plt.xlabel(\"Target (0 = No , 1 = Hypertensive)\")\n",
    "plt.ylabel(\"Capitation Coefficient (Socioeconomic Proxy)\")\n",
    "plt.xticks([0, 1], ['No', 'Hypertensive'])\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Group by target and calculate mean and standard deviation of capitation coefficient\n",
    "summary_stats = df.groupby(\"Y\")[\"demog_capitationcoefficient\"].agg([\"mean\", \"std\", \"median\", \"count\"])\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "group_0 = df[df['Y'] == 0]['demog_capitationcoefficient'].dropna()\n",
    "group_1 = df[df['Y'] == 1]['demog_capitationcoefficient'].dropna()\n",
    "\n",
    "# T-test\n",
    "t_stat, p_value = ttest_ind(group_0, group_1, equal_var=False)\n",
    "print(f\"T-test: T-stat={t_stat:.2f} p-value: {p_value:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Socioeconomic Status and Hypertensive Disorders\n",
    "To evaluate the relationship between socioeconomic status (proxied by demog_capitationcoefficient) and hypertensive disorders:\n",
    "\n",
    "- The mean capitation coefficient was slightly higher among patients who developed HDP (Y=1: 0.742) compared to those who did not (Y=0: 0.720).\n",
    "\n",
    "- Both groups had the same median (0.74), but variance was higher in the HDP group.\n",
    "\n",
    "A t-test confirmed that the difference in means is statistically significant:\n",
    "\n",
    "t = -3.83, p = 0.00015\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Socioeconomic status shows a weak but statistically significant association with hypertensive outcomes. While not a strong standalone predictor, it may contribute useful signal when combined with clinical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation with Target\n",
    "Show features most correlated with the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Description:\n",
    "\n",
    "\n",
    "- The prediction is made at Week 15 of gestation so only features available up to that point can be used as model inputs to avoid data leakage.\n",
    "\n",
    "- The cohort includes only low and moderate risk pregnancies. High-risk patients are excluded as they are already referred for testing.\n",
    "\n",
    "- The target variable Y indicates whether a hypertensive complication (e.g., preeclampsia, gestational hypertension, or eclampsia) occurred later in pregnancy.\n",
    "\n",
    "- Source flags (e.g., diagnosis codes, aspirin prescription) indicate how the outcome was identified and are useful for label validation, NOT for prediction. These features are derived after Week 15 and must not be used as predictors to avoid data leakage.\n",
    "\n",
    "- An initial scan of the dataset reveals that 45 columns have over 80% missing values. These features are unlikely to contribute meaningful signals and may introduce noise or instability in the model.\n",
    "\n",
    "- Diagnostic subtype columns (e.g., preeclampsia_sum, pregnancy_hypertension_sum, eclampsia_sum) are also excluded from modeling and correlation analysis. These variables are generated based on post-week-15 diagnosis data and therefore reflect the outcome itself. Including them would result in data leakage and overestimation of predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "df = pd.read_csv(path)\n",
    "\n",
    "#remove source flags and subtype columns\n",
    "numeric_cols = [\n",
    "    col for col in df.select_dtypes(include=[np.number]).columns # Select numeric columns only\n",
    "    if not col.startswith('match_') and not col.endswith('_sum')\n",
    "]\n",
    "\n",
    "# Compute full correlation matrix (pairwise deletion)\n",
    "corr_matrix = df[numeric_cols].corr(method=\"pearson\")\n",
    "\n",
    "# Build an n_pairs matrix: number of non‑NaN pairs for every column pair\n",
    "non_na = df[numeric_cols].notna().astype(int)\n",
    "n_pairs_matrix = non_na.T.dot(non_na)    # dot‑product counts pairwise valid rows\n",
    "\n",
    "# Extract correlation & n_pairs versus the target Y\n",
    "corr_vs_y = corr_matrix[\"Y\"].drop(\"Y\")           # remove self‑correlation\n",
    "n_pairs_vs_y = n_pairs_matrix[\"Y\"].drop(\"Y\")\n",
    "\n",
    "result = (\n",
    "    pd.DataFrame({\n",
    "        \"corr\": corr_vs_y,\n",
    "        \"abs_corr\": corr_vs_y.abs(),\n",
    "        \"n_pairs\": n_pairs_vs_y\n",
    "    })\n",
    "    .sort_values(\"abs_corr\", ascending=False)\n",
    ")\n",
    "\n",
    "# Show the full table or just the top‑ 20\n",
    "print(\"=== Correlation vs. Y (with n_pairs) – top 20 ===\\n\")\n",
    "print(result.head(20).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top correlated features with Y include:\n",
    "\n",
    "- Diagnosis recency features like 24_diag_53_days_since_last_diag (r = 0.34) and 4_diag_98_days_since_last_diag (r = 0.31)\n",
    "\n",
    "- Blood pressure stats (e.g., systolic/diastolic mean, max, last) show consistent moderate correlation (~0.12–0.14)\n",
    "\n",
    "- Weight at lab time also shows a mild positive signal (r = 0.11)\n",
    "\n",
    "⚠️ Some diagnosis features have few samples (n_pairs < 30), but due to their strong signal, I keep them for now and will handle sparsity via feature engineering later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a clean function to only fill age where missing, using text\n",
    "def fill_age_from_text(df):\n",
    "    def extract_age_from_text(text):\n",
    "        match = re.search(r'\\b(?:|בת|גיל)\\s{0,3}(\\d{2})\\b', str(text))\n",
    "        if match:\n",
    "            age = int(match.group(1))\n",
    "            if 15 <= age <= 60:\n",
    "                return age\n",
    "        return None\n",
    "\n",
    "    # Extract candidate age from text\n",
    "    df['age_from_text'] = df['clinical_sheet'].apply(extract_age_from_text)\n",
    "\n",
    "    # Fill only where missing\n",
    "    df.loc[df['demog_customer_age'].isna(), 'demog_customer_age'] = df.loc[\n",
    "        df['demog_customer_age'].isna(), 'age_from_text'\n",
    "    ]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "missing_age_before =  df[df['demog_customer_age'].isna()]\n",
    "# Apply function to fill missing age from clinical text\n",
    "df_after = fill_age_from_text(df)\n",
    "\n",
    "missing_age_after = df_after[df_after['demog_customer_age'].isna()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Befor:\" ,missing_age_before['demog_customer_age'])\n",
    "print(\"After: \",missing_age_after['demog_customer_age'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Patients with Multiple Missing Demographics\n",
    "After analyzing the 9 patients with missing demog_customer_age, I observed that these same patients were also missing critical demographic variables:\n",
    "\n",
    "demog_capitationcoefficient\n",
    "\n",
    "All smoking-related features (smoking_is_smoker, smoking_smoking_years, etc.)\n",
    "\n",
    "Since these records lacked multiple key inputs and none of them were positive cases (Y=1), I chose to remove them entirely from the dataset to maintain data quality and avoid noisy imputation.\n",
    "\n",
    "This left a final dataset with 9,991 valid patient records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoking cols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Check if the smoking related columns have missing values in the same rows\n",
    "smoking_cols = ['smoking_is_smoker', 'smoking_smoking_years', 'smoking_total_heavy_smokers']\n",
    "smoking_na_matrix = df[smoking_cols].isna()\n",
    "\n",
    "# Check how many rows have all 3 missing\n",
    "all_missing = smoking_na_matrix.all(axis=1).sum()\n",
    "\n",
    "# Check how many rows have partial missing (some but not all)\n",
    "partial_missing = smoking_na_matrix.any(axis=1).sum() - all_missing\n",
    "\n",
    "all_missing, partial_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Smoking Data\n",
    "There are 3,269 patients (nearly one third of the dataset) with missing values for all three smoking related features.\n",
    "Rather than removing these rows, I chose to retain them and apply a targeted imputation strategy:\n",
    "\n",
    "smoking_is_smoker: Filled from text where possible. If no information was found, defaulted to 0 (non-smoker), with a missing indicator added.\n",
    "\n",
    "smoking_smoking_years and smoking_total_heavy_smokers: Filled with 0 only when the patient was inferred as a non-smoker. Missingness was captured via indicator columns.\n",
    "\n",
    "This approach preserves valuable data and allows the model to handle uncertainty effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload dataset\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Count missing values for all lab_ columns\n",
    "lab_missing_summary = df.filter(like='lab_').isna().sum().sort_values(ascending=False)\n",
    "\n",
    "lab_missing_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values in Lab Features\n",
    "Most lab_ features had very few missing values (between 1–74 records), which is negligible.\n",
    "These were filled using the median, with corresponding missing indicator columns added.\n",
    "\n",
    "The lab_Protein-U_last_value feature had a higher missing rate (~42%).\n",
    "For simplicity, I also filled it with the median and added a missing indicator.\n",
    "In a full production setting, I would consider exploring the missingness mechanism or use predictive imputation techniques for this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Blood Pressure data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find missing values in cols that start with measure_blood_pressure\n",
    "bp_cols = [col for col in df.columns if col.startswith('measure_blood_pressure')]\n",
    "bp_missing_summary = df[bp_cols].isna().sum().sort_values(ascending=False)\n",
    "\n",
    "# Check if the missing data is on the same rows \n",
    "bp_missing_matrix = df[bp_cols].isna()\n",
    "n_rows_with_all_missing = bp_missing_matrix.all(axis=1).sum()\n",
    "n_rows_with_partial_missing = bp_missing_matrix.any(axis=1).sum() - n_rows_with_all_missing\n",
    "\n",
    "bp_missing_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values in Blood Pressure Features\n",
    "About 50% of the patients were missing all blood pressure features.\n",
    "Since this likely reflects a clinical decision not to measure BP in low-risk women, I filled all missing values with -1 and added a binary indicator (has_bp_data) to capture the presence of any BP measurements.\n",
    "This lets the model distinguish between low values and true missingness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_missing_values(df):\n",
    "    # 1. Labs: fill with median and create _missing indicators\n",
    "    lab_cols = [col for col in df.columns if col.startswith('lab_')]\n",
    "    for col in lab_cols:\n",
    "        if df[col].isna().any():\n",
    "            df[f'{col}_missing'] = df[col].isna().astype(int)\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # 2. Free-text field: clinical notes\n",
    "    df['clinical_sheet'] = df['clinical_sheet'].fillna('')\n",
    "\n",
    "    # 3. Capitation coefficient - only 9 values are missing and is the same with the age raw will remove. \n",
    "    # to be sure the rest if have na value complete it with meadian\n",
    "    if 'demog_capitationcoefficient' in df.columns:\n",
    "        df['demog_capitationcoefficient_missing'] = df['demog_capitationcoefficient'].isna().astype(int)\n",
    "        df['demog_capitationcoefficient'] = df['demog_capitationcoefficient'].fillna(\n",
    "            df['demog_capitationcoefficient'].median()\n",
    "        )\n",
    "\n",
    "    # 4. Customer age — drop rows where it was missing - only 9 is missing\n",
    "    df = df[df['demog_customer_age'].notna()].reset_index(drop=True)\n",
    "\n",
    "    # 5. Smoking\n",
    "    # Fill smoking_is_smoker using text_says_smoker if available\n",
    "    if 'text_says_smoker' in df.columns and 'smoking_is_smoker' in df.columns:\n",
    "        mask = df['smoking_is_smoker'].isna() & df['text_says_smoker'].notna()\n",
    "        df.loc[mask, 'smoking_is_smoker'] = df.loc[mask, 'text_says_smoker']\n",
    "    \n",
    "    # Fill the rest of smoking_is_smoker with 0 (default = non-smoker)\n",
    "    df['smoking_is_smoker_missing'] = df['smoking_is_smoker'].isna().astype(int)\n",
    "    df['smoking_is_smoker'] = df['smoking_is_smoker'].fillna(0)\n",
    "\n",
    "    # Now conditionally fill other smoking features\n",
    "    # smoking_smoking_years\n",
    "    if 'smoking_smoking_years' in df.columns:\n",
    "        df['smoking_smoking_years_missing'] = df['smoking_smoking_years'].isna().astype(int)\n",
    "        df.loc[(df['smoking_smoking_years'].isna()) & (df['smoking_is_smoker'] == 0), 'smoking_smoking_years'] = 0\n",
    "\n",
    "    # smoking_total_heavy_smokers\n",
    "    if 'smoking_total_heavy_smokers' in df.columns:\n",
    "        df['smoking_total_heavy_smokers_missing'] = df['smoking_total_heavy_smokers'].isna().astype(int)\n",
    "        df.loc[(df['smoking_total_heavy_smokers'].isna()) & (df['smoking_is_smoker'] == 0), 'smoking_total_heavy_smokers'] = 0\n",
    "    \n",
    "    # 6. Blood Pressure: create has_bp_data indicator, fill missing with -1\n",
    "    bp_cols = [col for col in df.columns if col.startswith('measure_blood_pressure')]\n",
    "    df['has_bp_data'] = (~df[bp_cols].isna().all(axis=1)).astype(int)\n",
    "    df[bp_cols] = df[bp_cols].fillna(-1)\n",
    "    \n",
    "    # 7. fill diagnosis columns - Fill NaNs with 999 to indicate \"no diagnosis\"\n",
    "    diag_4m_cols = [col for col in df.columns if col.startswith('4_diag_') and 'days_since_last_diag' in col]\n",
    "    diag_24m_cols = [col for col in df.columns if col.startswith('24_diag_') and 'days_since_last_diag' in col]\n",
    "    df[diag_4m_cols] = df[diag_4m_cols].fillna(999)\n",
    "    df[diag_24m_cols] = df[diag_24m_cols].fillna(999)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "print(df.shape)\n",
    "df_missing = preprocess_missing_values(df)\n",
    "df_missing.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values \n",
    "nan_check = df_missing.isna().sum()\n",
    "print(nan_check[nan_check > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnosis History Strategy:\n",
    "Raw *_days_since_last_diag columns are excluded from the model\n",
    "Instead, I engineered aggregate features:\n",
    " - num_recent_diags_4m / 24m\n",
    " - min_days_since_diag_4m / 24m\n",
    " - recency_score_4m / 24m\n",
    " \n",
    "These retain the clinical signal in a compressed, generalizable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_diagnosis_features(df):\n",
    "    # Identify relevant diagnosis columns\n",
    "    diag_4m_cols = [col for col in df.columns if col.startswith('4_diag_') and 'days_since_last_diag' in col]\n",
    "    diag_24m_cols = [col for col in df.columns if col.startswith('24_diag_') and 'days_since_last_diag' in col]\n",
    "\n",
    "    # Fill NaNs with 999 to indicate \"no diagnosis\"\n",
    "    df[diag_4m_cols] = df[diag_4m_cols].fillna(999)\n",
    "    df[diag_24m_cols] = df[diag_24m_cols].fillna(999)\n",
    "\n",
    "    # Create binary flags: whether diagnosis exists in time window\n",
    "    diag_4m_flags = df[diag_4m_cols] < 999\n",
    "    diag_24m_flags = df[diag_24m_cols] < 999\n",
    "\n",
    "    # Aggregated features\n",
    "    df['num_recent_diags_4m'] = diag_4m_flags.sum(axis=1)\n",
    "    df['num_recent_diags_24m'] = diag_24m_flags.sum(axis=1)\n",
    "    df['min_days_since_diag_4m'] = df[diag_4m_cols].min(axis=1).clip(upper=150)\n",
    "    df['min_days_since_diag_24m'] = df[diag_24m_cols].min(axis=1).clip(upper=730)\n",
    "    df['recency_score_4m'] = np.exp(-df['min_days_since_diag_4m'] / 30)\n",
    "    df['recency_score_24m'] = np.exp(-df['min_days_since_diag_24m'] / 90)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply to your dataframe\n",
    "diagnosis_df = generate_diagnosis_features(df)\n",
    "diagnosis_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Clinical Text Features:\n",
    "The free-text clinical notes (clinical_sheet) were processed using the following steps:\n",
    "\n",
    "Text Cleaning\n",
    "Removed irrelevant numeric entities (e.g., weights, ages, years) and punctuation to reduce noise in the text.\n",
    "\n",
    "TF-IDF Vectorization\n",
    "Transformed the cleaned text into numerical features using Term Frequency–Inverse Document Frequency (TF-IDF) with a limit of 500 features.\n",
    "\n",
    "Dimensionality Reduction (SVD)\n",
    "Applied Truncated SVD to reduce the TF-IDF features to 50 components (txt_svd_0 to txt_svd_49), capturing the main semantic signals while minimizing dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical Text Features\n",
    "\n",
    "def extract_text_features(df, text_column='clinical_sheet', max_features=500, svd_components=50):\n",
    "    def clean_clinical_text(text):\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'\\d{2,3}\\s?(kg|cm|years?|שנים|ק\"ג|קג)', '', text)\n",
    "        text = re.sub(r'\\d{4}', '', text)  # remove years like 1992, 2021\n",
    "        text = re.sub(r'\\n|\\r', ' ', text)\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
    "        return text.strip()\n",
    "\n",
    "    # Step 1: Clean the text\n",
    "    df['clinical_text_clean'] = df[text_column].fillna('').map(clean_clinical_text)\n",
    "\n",
    "    # Step 2: TF-IDF Vectorization\n",
    "    tfidf = TfidfVectorizer(max_features=max_features)\n",
    "    X_tfidf = tfidf.fit_transform(df['clinical_text_clean'])\n",
    "\n",
    "    # Step 3: Dimensionality Reduction\n",
    "    svd = TruncatedSVD(n_components=svd_components, random_state=42)\n",
    "    X_text_features = svd.fit_transform(X_tfidf)\n",
    "\n",
    "    # Step 4: Merge with original DataFrame\n",
    "    tfidf_feature_names = [f'txt_svd_{i}' for i in range(X_text_features.shape[1])]\n",
    "    df_tfidf = pd.DataFrame(X_text_features, columns=tfidf_feature_names, index=df.index)\n",
    "\n",
    "    return df_tfidf\n",
    "\n",
    "# Apply the function now\n",
    "df = extract_text_features(df)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define full feature engineering pipeline\n",
    "def full_feature_engineering(df):\n",
    "    # ==== 1. Blood Pressure Features ====\n",
    "    df['bp_sys_range'] = df['measure_blood_pressure_sys_max_val'] - df['measure_blood_pressure_sys_min_val']\n",
    "    df['bp_sys_trend'] = df['measure_blood_pressure_sys_last_val'] - df['measure_blood_pressure_sys_first_val']\n",
    "    df['bp_high_flag'] = ((df['measure_blood_pressure_sys_mean_val'] > 130) | \n",
    "                          (df['measure_blood_pressure_dias_mean_val'] > 85)).astype(int)\n",
    "    df['bp_x_age'] = df['measure_blood_pressure_sys_mean_val'] * df['demog_customer_age']\n",
    "\n",
    "    # ==== 2. Lab-Based Features ====\n",
    "    df['neutro_to_lymph_ratio'] = df['lab_Neutrophils_1_last_value'] / (df['lab_Lymphocytes_1_last_value'] + 1e-5)\n",
    "    df['hgb_low_flag'] = (df['lab_Hemoglobin (HGB)_last_value'] < 11).astype(int)\n",
    "\n",
    "    # ==== 3. Text Feature ====\n",
    "    df['txt_length'] = df['clinical_sheet'].fillna('').apply(lambda x: len(str(x).split()))\n",
    "\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df = full_feature_engineering(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload dataset\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# ==== Step 1: Preprocess missing values ====\n",
    "df = preprocess_missing_values(df)\n",
    "\n",
    "# ==== Step 2: Generate text features ====\n",
    "df_text_features = extract_text_features(df)\n",
    "df = pd.concat([df, df_text_features], axis=1)\n",
    "\n",
    "# ==== Step 3: Feature engineering ====\n",
    "df = generate_diagnosis_features(df)\n",
    "df = full_feature_engineering(df)\n",
    "\n",
    "# ==== Step 4: Remove subtype and diagnosis col start with 4/24_diag ====\n",
    "df = df.drop(columns=[col for col in df.columns \n",
    "                     if (col.startswith('match_') and not col.endswith('_sum')) or\n",
    "                        (col.startswith('4_diag_') and 'days_since_last_diag' in col) or\n",
    "                        (col.startswith('24_diag_') and 'days_since_last_diag' in col) or\n",
    "                        col.endswith('_sum')])\n",
    "\n",
    "# ==== Step 5: Feature selection ====\n",
    "exclude_cols = [\n",
    "    'Y', 'clinical_sheet', 'clinical_text_clean', 'text_says_smoker', 'int_date'\n",
    "]\n",
    "X = df[[col for col in df.columns if col not in exclude_cols]]\n",
    "y = df['Y']\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one combined DataFrame\n",
    "df_combined = X.copy()\n",
    "df_combined['target'] = y\n",
    "\n",
    "# Export to CSV\n",
    "df_combined.to_csv('/Users/danielmashala/dev/code/ds_code/Maccabi_Home_Task/X_y_combined.csv', index=False)\n",
    "\n",
    "print(f\"Combined table exported with shape: {df_combined.shape}\")\n",
    "print(f\"Features: {len(df_combined.columns) - 1}\")  # -1 for target column\n",
    "print(f\"Target column: 'target'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Train/test split - use stratify to balance the y label in train and test datasets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate scale_pos_weight to handle class imbalance in XGBoost\n",
    "# Formula: scale_pos_weight = (Number of Negative Samples) / (Number of Positive Samples)\n",
    "neg_count = (y == 0).sum()\n",
    "pos_count = (y == 1).sum()\n",
    "scale_pos_weight = neg_count / pos_count\n",
    "\n",
    "\n",
    "# Train models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=100, eval_metric='logloss', random_state=42, scale_pos_weight=scale_pos_weight)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "xgb_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "rf_auc = roc_auc_score(y_test, rf_proba)\n",
    "xgb_auc = roc_auc_score(y_test, xgb_proba)\n",
    "report_rf = pd.DataFrame(classification_report(y_test, rf_preds, output_dict=True)).transpose().round(3)\n",
    "report_xgb = pd.DataFrame(classification_report(y_test, xgb_preds, output_dict=True)).transpose().round(3)\n",
    "report_rf.loc['AUC'] = [rf_auc, '', '', '']\n",
    "report_xgb.loc['AUC'] = [xgb_auc, '', '', '']\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    \"\"\"Plot confusion matrix for a model\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Create and plot with blue colormap\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1]).plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"{model_name} Results:\")\n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    print(f\"Precision: {tp/(tp+fp):.3f}\")\n",
    "    print(f\"Recall: {tp/(tp+fn):.3f}\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Classification Report:\")\n",
    "report_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "plot_confusion_matrix(y_test, rf_preds, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model Evaluation – Confusion Matrix Summary\n",
    "\n",
    "he confusion matrix summarizes the prediction performance of the Random Forest model trained with class_weight='balanced'.\n",
    "\n",
    "Key Observations:\n",
    "- The model predicted only 2 true positives out of 86 actual class 1 cases → recall of just ~2.3%.\n",
    "\n",
    "- While precision for class 1 was perfect (1.0), this is misleading because the model barely predicted any positives at all.\n",
    "\n",
    "- It achieved zero false positives, indicating extreme caution — but at the cost of missing nearly all the true cases.\n",
    "\n",
    "- Despite a decent overall accuracy (95.8%), the model failed in the primary business goal: identifying high-risk pregnancies early.\n",
    "\n",
    "Conclusion:\n",
    "- Random Forest, even with class balancing, showed very poor recall for the minority class (patients with hypertensive conditions).\n",
    "\n",
    "- The model appears to be overly conservative, effectively ignoring the positive class to avoid false positives.\n",
    "\n",
    "- This behavior makes it unsuitable for clinical risk prediction where recall (sensitivity) is far more critical than overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"XGBoost Classification Report:\")\n",
    "report_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, xgb_preds, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model Evaluation – Confusion Matrix Summary\n",
    "\n",
    "The confusion matrix summarizes the prediction performance of the XGBoost model, trained with class imbalance handling using scale_pos_weight.\n",
    "\n",
    "Key Observations:\n",
    "- The model correctly identified 50 out of 86 true positive cases (recall ≈ 58.1%).\n",
    "\n",
    "- It made only 10 false positive predictions, indicating a high precision of ~83.3% for class 1.\n",
    "\n",
    "- Overall accuracy was 97.7%, with an excellent AUC of 0.974, indicating strong discriminative power.\n",
    "\n",
    "- The balance between sensitivity (recall) and specificity (TN rate) is particularly important in clinical risk screening, where missing true positives could result in serious complications.\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "- XGBoost performed well on this imbalanced medical dataset, successfully identifying a substantial portion of high-risk pregnancies.\n",
    "\n",
    "- Its high precision and reasonable recall make it a strong candidate for clinical decision support systems, especially when early detection is critical and false positives are tolerable under cost-effective interventions like aspirin administration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screening Prioritization – Model-Based Ranking\n",
    "An XGBoost model was trained to assign each patient a risk score indicating the likelihood of developing a hypertensive disorder. Instead of using the model for binary classification, patients were ranked by predicted risk, and performance was evaluated at various Top-K thresholds (representing different screening budget levels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ranking dataframe\n",
    "ranking_df = pd.DataFrame({\n",
    "    'patient_id': X_test.index,\n",
    "    'true_label': y_test.values,\n",
    "    'xgb_risk_score': xgb_proba\n",
    "}).sort_values(by='xgb_risk_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Evaluate at different budget thresholds\n",
    "k_values = [50, 100, 200, 300, 500]\n",
    "total_positives = ranking_df['true_label'].sum()\n",
    "ranking_summary = []\n",
    "\n",
    "for k in k_values:\n",
    "    top_k = ranking_df.head(k)\n",
    "    recall_at_k = top_k['true_label'].sum() / total_positives\n",
    "    precision_at_k = top_k['true_label'].sum() / k\n",
    "    ranking_summary.append({'Top K': k, 'Precision@K': precision_at_k, 'Recall@K': recall_at_k})\n",
    "\n",
    "ranking_metrics = pd.DataFrame(ranking_summary)\n",
    "ranking_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "\n",
    "- Screening the top 100–200 patients captures the majority of true positive cases while limiting the number of costly lab tests.\n",
    "\n",
    "- This ranking approach is suitable for screening prioritization when resources are limited and early detection is critical.\n",
    "\n",
    "- Precision declines as K increases, as expected, while recall improves — reflecting a typical trade-off in prioritization.\n",
    "\n",
    "\n",
    "Model Improvement & Future Work: \n",
    "- Feature Importance Analysis\n",
    "Use XGBoost gain-based importance to remove low-impact features and focus on key drivers.\n",
    "\n",
    "- Hyperparameter Tuning\n",
    "Apply Grid Search or Optuna to optimize tree depth, learning rate, regularization, and more.\n",
    "\n",
    "- Feature Engineering\n",
    "Enhance signal by adding lab ratios, trends, and domain-informed interactions (e.g., age × blood pressure).\n",
    "\n",
    "- Improved Text Embeddings (for Hebrew)\n",
    "Instead of TF-IDF, experiment with multilingual embeddings or Hebrew-specific models such as AlephBERT for richer clinical text representation.\n",
    "\n",
    "- Probability Calibration & Threshold Tuning\n",
    "Calibrate output scores and fine-tune classification thresholds for better prioritization.\n",
    "\n",
    "- Add More Positive Samples\n",
    "Expanding the dataset with more Y=1 cases can improve model learning and performance in imbalanced settings.\n",
    "\n",
    "- Diagnosis Source Analysis\n",
    "Use match_*_after fields to evaluate how the model performs across different diagnosis types and explore multi-label classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budget-Constrained Evaluation\n",
    "To simulate a fixed testing budget, I ranked patients by their predicted risk (from the XGBoost model) and measured model performance at different Top-K thresholds — representing the number of patients that could be tested.\n",
    "\n",
    "For example, assuming a budget to test only the top 100 patients (out of 2000 in the test set), the model achieves:\n",
    "\n",
    "- Precision@100 = 61% (i.e., 61 out of 100 were true cases)\n",
    "\n",
    "- Recall@100 = 70.9% (i.e., 70.9% of all true cases in the test set were captured)\n",
    "\n",
    "This provides a practical framework to select patients for testing when resources are limited, ensuring high-risk patients are prioritized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define Precision@K and Recall@K values from earlier results\n",
    "top_k = [50, 100, 200, 300, 500]\n",
    "precision_at_k = [0.88, 0.61, 0.385, 0.263, 0.168]\n",
    "recall_at_k = [0.5116, 0.7093, 0.8953, 0.9186, 0.9767]\n",
    "\n",
    "# Assume test set has same distribution: 86 positives out of 1999 total\n",
    "baseline_pos_rate = 86 / 1999\n",
    "\n",
    "# Plot Recall@K and Precision@K vs Top-K\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(top_k, precision_at_k, marker='o', label='Precision@K')\n",
    "plt.plot(top_k, recall_at_k, marker='o', label='Recall@K')\n",
    "plt.axhline(y=baseline_pos_rate, color='gray', linestyle='--', label='Baseline Pos Rate (Random Selection)')\n",
    "plt.xlabel(\"Top-K Patients (Testing Budget)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Budget-Constrained Evaluation: Precision@K and Recall@K\")\n",
    "plt.xticks(top_k)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budget-Constrained Evaluation plot showing how well the model performs under different screening budgets:\n",
    "\n",
    "Interpretation:\n",
    "Precision@K drops as K increases, more patients tested = more false positives.\n",
    "\n",
    "Recall@K improves as K increases — testing more patients captures more true cases.\n",
    "\n",
    "The gray line represents the baseline positive rate (~4.3%) you'd get from random selection.\n",
    "\n",
    "This clearly shows the value of the model:\n",
    "→ At K = 100, the model captures ~70% of all true cases with precision 14× better than random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation & Recommendations\n",
    " \n",
    "Feature Interpretation:\n",
    "The XGBoost model identifies several key predictors of hypertensive disorders:\n",
    "\n",
    "- Blood Pressure Features:\n",
    "Systolic and diastolic values — including trends and maximum readings — were among the most influential signals, suggesting early signs of elevated risk.\n",
    "\n",
    "- Diagnosis History (4–24 months):\n",
    "The number of recent diagnoses and how recent they were (recency score) strongly influenced predictions. Patients with multiple or recent events had higher risk scores.\n",
    "\n",
    "- Lab Values:\n",
    "Hemoglobin levels and ratios such as neutrophil-to-lymphocyte showed strong correlations with adverse outcomes.\n",
    "\n",
    "- Demographics & Textual Features:\n",
    "Age, capitation coefficient, and structured text-based features contributed additional signals.\n",
    "\n",
    "The chart below shows the Top 20 most important features based on XGBoost gain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"importance\": xgb_model.feature_importances_\n",
    "}).sort_values(by=\"importance\", ascending=False).head(20)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df, x=\"importance\", y=\"feature\", palette=\"viridis\")\n",
    "plt.title(\"Top 20 Feature Importances (XGBoost)\")\n",
    "plt.xlabel(\"Gain Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screening Recommendations\n",
    "With limited testing resources, the model helps prioritize high-risk patients.\n",
    "\n",
    "- Top 100 patients: captures ~70% of true cases (Recall@100), with 61% precision.\n",
    "\n",
    "- Top 200 patients: raises coverage to ~90%.\n",
    "\n",
    "Thresholds can be adjusted to fit available budget, supporting efficient, targeted screening."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
